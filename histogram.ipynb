{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('env')",
   "metadata": {
    "interpreter": {
     "hash": "51da6c8bb7e6c992b980497d585c5701cdf791fcbbfe6dc9056c3f444d0f18f3"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import datetime \n",
    "from dateutil.parser import parse\n",
    "import nbformat\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining default folder structure\n",
    "RAW_DATA_FOLDER = 'data/raw/'\n",
    "OUTPUT_DATA_FOLDER = 'data/output/'\n",
    "REPORT_FOLDER = 'reports/'\n",
    "\n",
    "#sectors and countries that we are interested\n",
    "sector_list = ['Energy Storage & Management', 'Industry 4.0', 'Mobility & Automotive', 'Supply Chain & Logistics', 'Other']\n",
    "country_list = ['Germany', 'Turkey', 'United Kingdom', 'Other']\n",
    "\n",
    "#import the dataset\n",
    "pipeline = pd.read_csv(os.path.join(RAW_DATA_FOLDER, 'pipeline.csv'))\n",
    "#set_indexes([energy, industry, sc_logistics, mobility], [\"id\", \"id\", \"id\", \"id\"])\n",
    "\n",
    "#prints a cumulative histogram if TRUE\n",
    "CUMULATIVE = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize the date input\n",
    "pipeline.rename(columns={'Day Created': 'Date'}, inplace=True)\n",
    "pipeline.loc[~pipeline['Country'].isin(country_list), 'Country'] = 'Other'\n",
    "#get rid of irrelevant rows\n",
    "pipeline.dropna(subset = ['Sector'], inplace=True)\n",
    "pipeline.replace(\"-\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline[pipeline[\"Term Sheet Date\"].notnull()][\"Term Sheet Date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust time format\n",
    "pipeline[\"Date\"] = pd.to_datetime(pipeline[\"Date\"]).dt.strftime('%Y-%m-%d')\n",
    "pipeline[\"Date\"] = pipeline[\"Date\"].apply(lambda x : parse(x))\n",
    "pipeline[\"One Pager Date\"] = pd.to_datetime(pipeline[\"One Pager Date\"]).dt.strftime('%Y-%m-%d')\n",
    "pipeline[\"One Pager Date\"] = pipeline[pipeline[\"One Pager Date\"].notnull()]['One Pager Date'].apply(lambda x : parse(x))\n",
    "pipeline[\"Term Sheet Date\"] = pd.to_datetime(pipeline[\"Term Sheet Date\"]).dt.strftime('%Y-%m-%d')\n",
    "pipeline[\"Term Sheet Date\"] = pipeline[pipeline[\"Term Sheet Date\"].notnull()]['Term Sheet Date'].apply(lambda x : parse(x))\n",
    "pipeline[\"Closing Date\"] = pd.to_datetime(pipeline[\"Closing Date\"]).dt.strftime('%Y-%m-%d')\n",
    "pipeline[\"Closing Date\"] = pipeline[pipeline[\"Closing Date\"].notnull()]['Closing Date'].apply(lambda x : parse(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#array(['First Look', 'Term Sheet', 'One Pager', 'Invested'], dtype=object)\n",
    "invested_mask = pipeline['First Look'] == 'Invested'\n",
    "invested_count = pipeline[invested_mask][['Name']].count()\n",
    "\n",
    "term_sheet_mask = invested_mask | (pipeline['First Look'] == 'Term Sheet')\n",
    "term_sheet_count = pipeline[term_sheet_mask][['Name']].count()\n",
    "\n",
    "one_pager_mask = term_sheet_mask | (pipeline['First Look'] == 'One Pager')\n",
    "one_pager_count = pipeline[one_pager_mask][['Name']].count()\n",
    "\n",
    "first_look_mask = one_pager_mask | (pipeline['First Look'] == 'First Look')\n",
    "first_look_count = pipeline[first_look_mask][['Name']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the mask feature\n",
    "pipeline[one_pager_mask]['Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quarter Creator\n",
    "pipeline[\"First Look Quarter\"] = pipeline[first_look_mask][\"Date\"].dt.to_period(\"Q\")\n",
    "pipeline[\"One Pager Quarter\"] = pipeline[one_pager_mask][\"One Pager Date\"].dt.to_period(\"Q\")\n",
    "pipeline[\"Term Sheet Quarter\"] = pipeline[term_sheet_mask][\"Term Sheet Date\"].dt.to_period(\"Q\")\n",
    "pipeline[\"Invested Quarter\"] = pipeline[invested_mask][\"Closing Date\"].dt.to_period(\"Q\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CUMULATIVE:\n",
    "    invested_quarter = pipeline.groupby('Invested Quarter').size().cumsum().to_frame('Invested').reset_index().rename(columns={'Invested Quarter': 'Quarter'})\n",
    "    term_sheet_quarter = pipeline.groupby('Term Sheet Quarter').size().cumsum().to_frame('Term Sheet').reset_index().rename(columns={'Term Sheet Quarter': 'Quarter'})\n",
    "    one_pager_quarter = pipeline.groupby('One Pager Quarter').size().cumsum().to_frame('One Pager').reset_index().rename(columns={'One Pager Quarter': 'Quarter'})\n",
    "    first_look_quarter = pipeline.groupby('First Look Quarter').size().cumsum().to_frame('First Look').reset_index().rename(columns={'First Look Quarter': 'Quarter'})\n",
    "else:\n",
    "    invested_quarter = pipeline.groupby('Invested Quarter').size().to_frame('Invested').reset_index().rename(columns={'Invested Quarter': 'Quarter'})\n",
    "    term_sheet_quarter = pipeline.groupby('Term Sheet Quarter').size().to_frame('Term Sheet').reset_index().rename(columns={'Term Sheet Quarter': 'Quarter'})\n",
    "    one_pager_quarter = pipeline.groupby('One Pager Quarter').size().to_frame('One Pager').reset_index().rename(columns={'One Pager Quarter': 'Quarter'})\n",
    "    first_look_quarter = pipeline.groupby('First Look Quarter').size().to_frame('First Look').reset_index().rename(columns={'First Look Quarter': 'Quarter'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the value\n",
    "print(\"\"\" \n",
    "first_look: {}\n",
    "one_pager: {}\n",
    "term_sheet: {} \n",
    "invested: {}\n",
    "\"\"\".format(int(first_look_count), int(one_pager_count), int(term_sheet_count), int(invested_count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [invested_quarter, term_sheet_quarter, one_pager_quarter, first_look_quarter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge all dfs on Quarter column\n",
    "df_final = reduce(lambda left,right: pd.merge(left, right, on='Quarter', how='outer'), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace NaN values with 0\n",
    "df_final = df_final.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column type transformation\n",
    "df_final['Invested'] = df_final['Invested'].astype('int')\n",
    "df_final['Term Sheet'] = df_final['Term Sheet'].astype('int')\n",
    "df_final['One Pager'] = df_final['One Pager'].astype('int')\n",
    "df_final['First Look'] = df_final['First Look'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.sort_values('Quarter', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## time to visualize the data\n",
    "# Values of each group\n",
    "bars1 = list(df_final['One Pager'].values)\n",
    "bars2 = list(df_final['Invested'].values)\n",
    "bars3 = list(df_final['Term Sheet'].values)\n",
    "\n",
    "# Heights of bars1 + bars2\n",
    "bars = np.add(bars1, bars2).tolist()\n",
    " \n",
    "# The position of the bars on the x-axis\n",
    "r = list(np.arange(13))\n",
    " \n",
    "# Names of group and bar width\n",
    "names = list(df_final['Quarter'].astype(str))\n",
    "barWidth = 0.35\n",
    " \n",
    "# Create brown bars\n",
    "plt.bar(r, bars1, color='red', edgecolor='white', width=barWidth)\n",
    "# Create green bars (middle), on top of the firs ones\n",
    "plt.bar(r, bars2, bottom=bars1, color='green', edgecolor='white', width=barWidth)\n",
    "# Create blue bars (top)\n",
    "plt.bar(r, bars3, bottom=bars, color='blue', edgecolor='white', width=barWidth)\n",
    " \n",
    "# Custom X axis\n",
    "plt.xticks(r, names, fontweight='bold',rotation='vertical')\n",
    "\n",
    "plt.xlabel(\"Quarter\")\n",
    "plt.ylabel(\"Number\")\n",
    "plt.title(\"Number of Stages in Each Quarter\")\n",
    "\n",
    "# Custom Legend\n",
    "one_pager = mpatches.Patch(color='red', label='One Pager')\n",
    "invested = mpatches.Patch(color='green', label='Invested')\n",
    "term_sheet = mpatches.Patch(color='blue', label='Term Sheet')\n",
    "plt.legend(handles=[one_pager,invested,term_sheet], loc=2)\n",
    "\n",
    "plt.ylim([0, 10])\n",
    "\n",
    "# Show graphic\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}